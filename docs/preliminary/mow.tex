\documentclass{DTAS07}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{polski}
\usepackage[cp1250]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{url}

\title{IMPLEMENTACJA APROKSYMATORA CMAC\\
{\small Dokumentacja wstêpna projektu MOW}
}

\author{Micha³ Skrzêdziejewski, Micha³ Kozakiewicz}

\begin{document}
\bibliographystyle{ieeetr}
%\maketitle
\thispagestyle{empty}

\section{WSTÊP}
\subsection{Aproksymacja funkcji}
W praktyce in¿ynierskiej i badaniach naukowych czêsto powstaje potrzeba 
przybli¿enia pewnej funkcji. Funkcja ta mo¿e byæ trudna do obliczenia,
pomiary kosztowne a ich iloœæ ograniczona \cite{masters1993pnn}. W wielu przypadkach
wystarcza zastosowanie klasycznych metod numerycznych, takich jak regresja
liniowa, przybli¿enie wielomianami czy funkcjami sklejanymi (ang. {\em 
SPLINES}).
Zwykle mo¿na to uczyniæ, gdy jest siê w posiadaniu wiedzy na temat postaci 
aproksymowanej funkcji. Czêsto jednak funkcja ta jest nieznana a o jej postaci
nie mo¿na powiedzieæ nic. W szczególnoœci mo¿emy mieæ do czynienia z wysoce 
nieliniowym zjawiskiem z bli¿ej nieznanymi zale¿noœciami. W takim przypadku z 
pomoc¹ przychodz¹ ucz¹ce siê aproksymatory funkcji, takie jak CMAC który bêdzie
przedmiotem implementacji.

\subsection{Dziedzina i zbiór przyk³adów}
WeŸmy pod uwagê funkcjê docelow¹ $f:X \mapsto \Re^n$. Zauwa¿my, ¿e bez straty
ogólnoœci mo¿emy problem przybli¿enia tej funkcji zredukowaæ do problemu
przybli¿enia funkcji $f:X \mapsto \Re$. Da siê to osi¹gn¹æ poprzez z³o¿enie
$n$ pojedynczych klasyfikatorów, z których ka¿dy realizuje odwzorowanie 
$f:X \mapsto \Re$ dla konkretnego elementu wektora wartoœci oryginalnej funkcji.

Do dyspozycji mamy pewn¹ iloœæ przyk³adów z dziedziny $X$. Pojedynczy przyk³ad 
jest zwykle reprezentowany przez wektor atrybutów (cech) 
$\phi(x) = \langle \phi_0(x), \phi_1(x), \dots, \phi_n(x) \rangle$. Czêsto na koniec wektora atrybutów wstawia siê na sta³e atrybut $\phi_n(x) = 1$. Mo¿na tu zauwa¿yæ analogiê do regresji liniowej, w której szukamy funkcji postaci $y = ax + b = \langle a, b \rangle \cdotp \langle x,1 \rangle$. Parametr b, który mo¿emy potraktowaæ jako wagê, pozwala nam regulowaæ po³o¿enie prostej. 

W przypadku wiêkszoœci metod aproksymacji funkcji musimy ograniczyæ siê do 
atrybutów o wartoœciach ci¹g³ych. Jeœli jednak przyk³ady posiadaj¹ atrybuty
nominalne lub porz¹dkowe, nale¿y dokonaæ odpowiedniego ich przekszta³cenia.
Oczywistym pomys³em jest nadanie tym atrybutom wartoœci liczbowych. Niestety, o
ile rozwi¹zanie to ma sens w przypadku atrybutów porz¹dkowych (np. $wtorek = 2$,
$czwartek = 4$, $sobota = 6)$, to w przypadku atrybutów nominalnych wprowadza 
ono nieuzasadniony porz¹dek (np. $mercedes = 1$, $audi = 2$, $fiat = 3$). 
Alternatyw¹ jest wprowadzenie dodatkowego atrybutu binarnego dla ka¿dej mo¿liwej
wartoœci atrybutu nominalnego. Prowadzi to jednak do zwiêkszenia wymiarowoœci 
problemu.

\subsection{Rodzaje aproksymatorów}
Nauczony aproksymator reprezentuje pewn¹ hipotezê $h(x)$ bêd¹c¹ przybli¿eniem
funkcji docelowej $f(x)$. Bior¹c jako kryterium podzia³u sposób reprezentacji 
hipotez, mo¿emy wyró¿niæ nastêpuj¹ce rodzaje klasyfikatorów \cite{cichosz2000sus}:
\begin{itemize}
\item {\bf parametryczne}, w których hipoteza jest reprezentowana przez 
wektor liczb rzeczywistych zwanych wagami (jest on modyfikowany w trakcie uczenia siê),
\item {\bf pamiêciowe}, które przechowuj¹ przyk³ady trenuj¹ce a odpowiedŸ dla
kolejnych przyk³adów wyznaczaj¹ na podstawie odpowiedzi zapamiêtanych przyk³adów zbli¿onych,
\item {\bf symboliczne}, wykorzystuj¹ce symboliczn¹ reprezentacje hipotez.
\end{itemize}
Przedmiotem naszych rozwa¿añ bêd¹ klasyfikatory parametryczne,
w których wartoœæ $h(x) = F(\phi(x),w)$, gdzie $F$ jest funkcj¹ opisuj¹c¹
zale¿noœæ wyjœæ aproksymatora od wektora atrybutów danego przyk³adu i
wektora wag. W wiêkszoœci przypadków funkcja $F$ ma ustalon¹ postaæ, wiêc do 
opisu hipotezy aproksymatora wystarcza sam wektor wag $w$.


\subsection{Proces uczenia siê}
Praktycznie wszystkie metody uczenia siê aproksymatorów parametrycznych opieraj¹
siê na minimalizacji funkcji b³êdu na zbiorze trenuj¹cym, któr¹ najczêœciej
przyjmujemy jako

\begin{align}
	e^f_P(h) = \frac{1}{|P|}\sum_{x\in P}(f(x)-h(x))^2.
	\label{eq:blad}
\end{align}

Minimalizacja tak zdefiniowanej funkcji b³êdu odbywa siê poprzez aktualizacjê
wektora wag. Klasyczn¹ metod¹ osi¹gniêcia tego celu jest metoda najwiêkszego
spadku (ang. {\em steepest descent}). Jest to metoda gradientowa, aktualizuj¹ca wektor wag zgodnie ze wzorem:

\begin{align}
	\Delta_w = -\beta \nabla_w \varepsilon_T^f(h_w)
\end{align}

gdzie $\beta$ oznacza tzw. rozmiar kroku a $\nabla_w \varepsilon_T^f(h_w)$ oznacza wektor pochodnych cz¹stkowych 
funkcji b³êdu wzglêdem poszczególnych wag. Sposób obliczenia pochodnych cz¹stkowych zale¿y od konkretnego modelu, np. dla sieci neuronowych typu MLP
otrzymuje siê go wykorzystuj¹c metodê propagacji wstecznej (ang. {\em back 
propagation}). Aktualizacja wag dokonuje siê zwykle w trybie wsadowym, czyli po 
przetworzeniu ca³ego zbioru trenuj¹cego. W ten sposób uniezale¿niamy wynik
nauczania od kolejnoœci prezentowanych przyk³adów.

Podstawowa metoda najwiêkszego spadku ³atwo utyka w minimach lokalnych. Z tego powodu w sieciach MLP u¿ywa siê bardziej skomplikowanych metod jak na przyk³ad 
metoda Levenberga-Marquardta.

\subsection{Ocena jakoœci modeli}
Dla aproksymatorów parametrycznych, proces uczenia siê polega na modyfikacji wag a¿ do osi¹gniêcia zamierzonego celu, którym jest zwykle minimalizacja funkcji b³êdu. Czêsto oprócz wyboru metody 
uczenia siê mamy tak¿e pewien wp³yw na strukturê samego modelu. W przypadku klasycznego perceptronu wielowarstwowego mo¿emy sterowaæ iloœci¹ 
neuronów warstwy ukrytej, lub (rzadziej) iloœci¹ warstw ukrytych. Dla aproksymatora CMAC takim parametrem jest iloœæ przedzia³ów na które dzielona jest dziedzina danego atrybutu a tak¿e liczba warstw. Naszym celem jest wybór 
modelu który jak najlepiej oddaje rzeczywist¹ funkcjê $f(x)$. Pomocne mog¹
byæ tu nastêpuj¹ce metody oceny zdolnoœci modelu do generalizacji\cite{dreyfus:mav}:
\begin{itemize}
\item {\bf Jednokrotny podzia³} (ang. {\em hold-out}). W tej metodzie dokonujemy losowego podzia³u przyk³adów na dwie grupy, z których pierwsza bêdzie u¿ywana w procesie nauczania a
druga do oceny uzyskanego modelu. Typowe proporcje wynosz¹ $70\%$ dla zbioru
trenuj¹cego i $30\%$ dla testowego. Metoda ta sprawdza siê dla stosunkowo du¿ych
zbiorów danych. Jej wad¹ jest to, ¿e byæ mo¿e istotne informacje ze zbioru 
testowego nie mog¹ byæ wykorzystane w procesie uczenia siê.

\item {\bf Ocena krzy¿owa} (ang. {\em cross-validation}). W klasycznej postaci tej metody dzielimy zbiór przyk³adów na $n$ podzbiorów. Nastêpnie odrzucamy jeden podzbiór a pozosta³e $n-1$ podzbiorów wykorzystujemy do nauczenia modelu. Odrzucony zbiór s³u¿y do obliczenia b³êdu modelu. Operacjê odrzucenia powtarzamy 
dla ka¿dego podzbioru a b³êdy uzyskane dla kolejno uzyskanych podzbiorów. 
W ten sposób ostateczna miara przydatnoœci modelu nie jest obci¹¿ona takim czy innym wyborem zbioru trenuj¹cego i testowego (jak w metodzie jednokrotnego podzia³u). Jest to dobre rozwi¹zanie w przypadku mniejszych zbiorów przyk³adów.

\item {\bf Skrajna ocena krzy¿owa} (ang {\em leave-one-out}). Jest to przypadek
graniczny omówionej wy¿ej metody oceny krzy¿owej, gdzie zbiór $m$ przyk³adów 
jest dzielony na $m$ jednoelementowych podzbiorów. Nastêpnie, kolejno, ka¿dy z nich jest usuwany, model uczony a odrzucony przyk³ad wykorzystany do obliczenia
cz¹stkowego b³êdu. Metoda ta jest stosowana w przypadku wyj¹tkowo ma³ych 
zbiorów przyk³adów. Jej niew¹tpliw¹ wad¹ jest kosztownoœæ obliczeniowa, gdy¿ 
proces uczenia musimy powtórzyæ tyle razy, ile jest przyk³adów. Prób¹ rozwi¹zania tego problemu jest metoda {\em virtual leave-one-out} bazuj¹ca na
pojêciu dŸwigni.
\end{itemize}

\subsection{Inne wykorzystanie aproksymatora}
Na koniec warto zauwa¿yæ, ¿e mo¿emy u¿yæ aproksymatora do rozwi¹zywania zadañ 
klasyfikacji, grupowania czy te¿ prognozowania szeregów czasowych. Nale¿y po 
prostu nadaæ wyjœciom modelu pewne znaczenie, zale¿ne od rozwi¹zywanego 
problemu. Przyk³adowo dla zadania klasyfikacji mo¿emy jedno z wyjœæ 
aproksymatora zdefiniowaæ jako prawdopodobieñstwo przynale¿noœci do danej klasy
i uwzglêdniæ tê interpretacjê w procesie uczenia.

\subsection{Aproksymator CMAC}
CMAC jest skrótem od angielskiej nazwy {\em Cereberral Model Articulation Controller}. Zosta³ on opisany przez J.S. Albusa w 1975 r. jako prosty model
kory mó¿d¿ku \cite{albus1975dsc, albus1975nam}. Od tego czasu powsta³o wiele ró¿nych odmian podstawowej wersji, a tak¿e interesuj¹cych zastosowañ, takich jak
sterowanie robotem pod¹¿aj¹cym za lini¹ \cite{collins1999ccl} czy 
zarz¹dzanie energi¹ w skuterach \cite{sinica:ice}. Podstawow¹ zalet¹ omawianego
aproksymatora jest szybkoœæ dzia³ania, zarówno jeœli chodzi o uczenie siê jak i
obliczanie odpowiedzi dla konkretnych wartoœci wejœæ. Fakt ten uzasadnia stosowanie go w adaptacyjnych systemach sterowania czasu rzeczywistego.

CMAC mo¿e byæ traktowany jako pewien szczególny rodzaj rozproszonego przybli¿onego kodowania, które z kolei wywodzi siê z ogólnej idei 
rozszerzonej reprezentacji \cite{cichosz2000sus}. Wiêkszoœæ opracowañ uznaje
CMAC za rodzaj sieci neuronowej, chocia¿ analogia nie jest tak wyraŸna jak w 
przypadku MLP (nie istniej¹ pojedyncze neurony, chocia¿ s¹ warstwy). Ze wzglêdów 
implementacyjnych wygodnie jest te¿ traktowaæ CMAC jako tablicê przegl¹dow¹ 
(ang. {\em lookup table}).

Zasadê dzia³ania CMACa naj³atwiej wyjaœniæ na przypadku jednowymiarowym
(jedno wejœcie, jedno wyjœcie). Przejœcie do przypadku z wektorem wejœæ 
o wiêkszej iloœci elementów nie nastrêcza trudnoœci. Za³ó¿my ¿e rozpatrywany
atrybut $\phi_0(x) \in (\phi_1^0, \phi_2^0]$. Podzielmy przedzia³ do którego 
nale¿y $\phi_0(x)$ na $m_0$ przyleg³ych podprzedzia³ów o równych d³ugoœciach. Zauwa¿my ¿e z ka¿dym przyk³adem $x$ mo¿emy zwi¹zaæ przedzia³ do którego ``wpada'' $x$ ze wzglêdu na atrybut $\phi_0(x)$. Dodatkowo zwi¹¿my z ka¿dym przedzia³em parametr rzeczywisty oznaczaj¹cy wagê. Utwórzmy teraz 2 kolejne podzia³y (warstwy), lecz tym razem wprowadŸmy przesuniêcie pocz¹tku 
podzia³u, jak na rysunku \ref{fig:przedzialy}. Zauwa¿my, ¿e teraz wartoœæ 
atrybutu determinuje 3 aktywne przedzia³y, po jednym dla ka¿dej warstwy.
Wielkoœæ wzglêdnego przesuniêcia kolejnej warstwy jest dobierana zwykle w nastêpuj¹cy sposób \cite{cichosz2000sus}:
\begin{align}
	\delta = \frac{d}{L}
\end{align}
gdzie $d$ jest szerokoœci¹ przedzia³u w pierwszej warstwie a $L$ liczb¹ warstw.
W ten sposób, podzia³y w warstwie $l$ bêd¹ przesuniête o $\delta$ w stosunku do
warstwy $l - 1$.
Warto zauwa¿yæ, ¿e przy podziale pierwszej warstwy na $n$ przedzia³ów, ka¿da
kolejna warstwa bêdzie podzielona na $n + 1$ przedzia³ów. 

Obliczenie wyjœcia dla aproksymatora jest proste i sprowadza siê do dodania
wag zwi¹zanych z przedzia³ami aktywowanymi przez dane wejœcie. Dla przyk³adu z 
rysunku \ref{fig:przedzialy} bêdzie to:

\begin{align*}
	h(x) = w_2 + w_8 + w_{13}.
\end{align*}

\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{przedz.pdf}
\caption{Aktywne przedzia³y dla zadanej wartoœci atrybutu}
\label{fig:przedzialy}
\end{figure}

Uogólnienie przedstawionej idei na n-wymiarowy wektor atrybutów nie jest skomplikowane. W szczególnoœci, dotychczasowy podzia³ na przedzia³y
bêdzie zast¹piony podzia³em n-wymiarowej przestrzeni na hiperszeœciany pe³ni¹ce
funkcje przedzia³ów.

\subsubsection{Uczenie siê}
Algorytm uczenia dla aproksymatora CMAC w swojej podstawowej wersji jest
bardzo prosty. Na pocz¹tek nale¿y wybraæ pocz¹tkow¹ wartoœæ wag. 
Mog¹ to byæ wartoœi wylosowane z jakiegoœ przedzia³u. Podajemy teraz na 
wejœcie aproksymatora przyk³ad $x_i$, co aktywuje $n$ wag, a na wyjœciu
otrzymujemy wartoœæ $y_i$. Chcemy, aby dla przyk³adu $x_i$ wyjœcie 
aproksymatora mia³o wartoœæ $t_i$, zmieniamy wiêc aktywne wagi zgodnie ze
wzorem:

\begin{align}
	w_i \gets w_i + \frac{\alpha}{n}(t_i - x_i)
\end{align}

gdzie $\alpha$ oznacza wspó³czynnik uczenia siê. Aby unikn¹æ 
wp³ywu kolejnoœci podawania przyk³adów na koñcow¹ wartoœæ wag, nale¿y
zsumowaæ zmiany wag dla ka¿dego przyk³adu, a nastêpnie, po prezentacji
ca³ego zbioru treningowego dokonaæ sumarycznej zmiany wag.

\subsubsection{Szczegó³y implementacyjne}
Istotnym pytaniem, jakie mo¿e siê nasun¹æ podczas rozwa¿añ na temat 
implementacji aproksymatora CMAC jest to, w jaki sposób przechowywane s¹ wagi.
Podejœcie naiwne, polegaj¹ce na przechowywaniu w pamiêci wielowymiarowej tablicy
liczb rzeczywistych jest zwykle nie do zrealizowania \cite{smith1998imc}.
Przybli¿ona liczba wag przechowywanych wag mo¿e byæ obliczona ze wzoru:

\begin{align}
	\frac{res^{(n_y)}}{n_a^{(n_y-1)}}
\end{align}

gdzie $res$ jest liczb¹ podzia³ów (zak³adamy sta³¹ dla ka¿dego atrybutu),
$n_y$ liczb¹ wejœæ a $n_a$ liczb¹ warstw. Dla przyk³adowych wartoœci
$res = 200$, $n_a = 10$, $n_y = 6$ wymagana liczba pamiêci to ok 
2Gb.

Aby rozwi¹zaæ ten problem u¿ywa siê tablic mieszaj¹cych (ang. {\em hash table}).
Zjawisko kolizji jest ignorowane, gdy¿ przyk³ady tylko w czêœci pokrywaj¹
przestrzeñ wejœciow¹, a co za tym idzie, aktywuj¹ tylko u³amek 
potencjalnie mo¿liwych do wykorzystania wag. W przypadku kolizji, ta sama waga
mo¿e byæ aktywowana przez dwa znacznie ró¿ni¹ce siê wektory wejœciowe. Zjawisko
zwykle nie powoduje wiêkszych problemów. Analizê wp³ywu kodowania mieszaj¹cego
na dzia³anie aproksymatora CMAC mo¿na znaleŸæ w \cite{wang1996hcc}.

\subsubsection{Uwagi}
Na koniec warto podkreœliæ kilka najistotniejszych cech aproksymatora CMAC:

\begin{itemize}
\item {\bf Szybkoœæ dzia³ania i uczenia siê}. Zarówno podczas uczenia siê, jak i w³aœciwego
dzia³ania, jeden przyk³ad aktywuje stosunkowo niewielk¹ liczbê wag. Umo¿liwia to
stosowanie CMAC'a w systemach on-line.
\item {\bf Skoñczona przestrzeñ wejœciowa}. Dla ka¿dego atrybutu nale¿y okreœliæ 
	skoñczony przedzia³, do którego bêd¹ nale¿a³y jego wartoœci.
\item {\bf Dyskretyzacja przestrzeni wejœciowej}. Dla pewnego otoczenia punktu
reprezentuj¹cego wektor wejœciowy, wyjœcie aproksymatora bêdzie sta³e.
\item {\bf Generalizacja lokalna}. W przeciwieñstwie do perceptronu wielowarstwowego, CMAC posiada jedynie lokaln¹ zdolnoœæ do generalizacji. Oznacza to, ¿e aby uzyskaæ dobr¹ generalizacjê, przestrzeñ przyk³adów musi byæ stosunkowo równomiernie pokryta zbiorem trenuj¹cym. 
\end{itemize}

\section{SZCZEGÓ£Y PROJEKTU}
\subsection{Cel projektu}
Celem projektu jest zaimplementowanie w jêzyku R aproksymatora CMAC oraz
porównanie z trzema innymi aproksymatorami, dostêpnymi w R:

\begin{itemize}
\item aproksymatorem liniowym (pakiet \em{stats}, funkcje \em{lm}, \em{glm}),
\item perceptronem wielowarstwowym (pakiet \em{nnet}),
\item maszyn¹ wektorów noœnych (pakiet \em{e1071}).
\end{itemize}

Aproksymator CMAC bêdzie uczony zgodnie z omówionym uprzednio algorytmem, natomiast pozosta³e aproksymatory bêd¹ uczone za pomoc¹ w³aœciwych dla siebie 
metod, dostêpnych w wykorzystywanych pakietach (np. dla MLP bêdzie to 
algorytm BFGS). 

Rozpatrywany model CMAC, jak i pozosta³e modele posiadaj¹ wiele parametrów od których zale¿y pomyœlnoœæ wykonania za³o¿onych celów. Zostan¹ przeprowadzone 
eksperymenty maj¹ce wy³oniæ jak najlepsze wartoœci tych parametrów dla konkretnego problemu. W przypadku, gdy liczba parametrów nie jest du¿a (np. dwa)
mo¿na bêdzie zastosowaæ jedno z omawianych wczeœniej kryteriów oceny modelu, w
zale¿noœci od rozmiaru prezentowanego zbioru danych.

\subsection{Dane}
Procesy uczenia siê i oceny jakoœci klasyfikatora wymagaj¹ z oczywistych 
wzglêdów dostatecznej liczby przyk³adów. Najprostsze jest u¿ycie pewnej znanej
funkcji do wygenerowania wymaganej ich liczby. Nieco bardziej miarodajne
mo¿e byæ u¿ycie przyk³adów uzyskanych z komputerowej symulacji jakiegoœ procesu.
Obie te metody maj¹ tê zaletê, ¿e liczba wygenerowanych przyk³adów nigdy nie 
jest zbyt ma³a. Jednak du¿o bardziej wymagaj¹cym, a jednoczeœnie ciekawszym 
badawczo podejœciem jest testowanie na ``rzeczywistych'' danych i g³ównie takie
dane zostan¹ wykorzystane w projekcie. Zestawy przyk³adów bêd¹ pochodziæ z
ogólnodostêpnych repozytoriów \cite{Asuncion+Newman:2007,guvenir2000buf}.

Ze wzglêdu na uprzednio zasygnalizowane problemy, wybrane zosta³o piêæ zestawów
przyk³adów wœród których nie wystêpuj¹ atrybuty nominalne i porz¹dkowe, lub
stanowi¹ niewielk¹ czêœæ wszystkich atrybutów (zgodnie z sugesti¹ prowadz¹cego projekt): 

\begin{itemize}
\item {\bf Weather Ankara}. Dane ze stacji pogodowej w Ankarze. 10 atrybutów 
	ci¹g³ych, atrybutem przewidywanym jest œrednia temperatura. Liczba elementów w zbiorze: 1609. Zbiór atrakcyjny ze wzglêdu na jedynie ci¹g³e atrybuty i brak 
nieznanych wartoœci.

\item {\bf Pollution}. Dane na temat zanieczyszczenia œrodowiska. 15 atrybutów
ci¹g³ych, wartoœci¹ przewidywan¹ jest œmiertelnoœæ. Liczba elementów w zbiorze: 60.
\item {\bf Stock Prices}. Codzienne notowania gie³dowe dotycz¹ce 10 spó³ek zwi¹zanych z lotnictwem. Przewidywan¹ wartoœci¹ jest cena spó³ki numer 10. 
Liczba elementów w zbiorze: 950.

\item {\bf Auto-Mpg}. Dane na temat samochodów. 4 atrybuty ci¹g³e, 2 porz¹dkowe, 1 nominalny, wartoœci¹ przewidywan¹ jest zu¿ycie paliwa wyra¿one w galonach na
milê. Liczba elementów w zbiorze: 398

\item {\bf Fat}. Dane pacjentów. 17 atrybutów ci¹g³ych, wartoœci¹ przewidywan¹ 
jest wzrost. Liczba elementów w zbiorze: 252.

Wybrane zbiory nie posiadaj¹ brakuj¹cych wartoœci, prawdopodobnie nie bêdzie wiêc konieczna wstêpna obróbka danych. W wypadku zestawu Auto-mpg bêdzie konieczna transformacja atrybutu nominalnego.
\end{itemize}

\subsection{Testy}
\subsubsection{Zdolnoœæ generalizacji}
Podstawowym kryterium oceny aproksymatorów bêdzie zdolnoœæ do generalizacji. 
Na pocz¹tku dokonany zostanie wybór architektury aproksymatorów dla konkretnego zestawu danych (np. iloœæ neuronów warstwy ukrytej dla MLP) metod¹ zale¿n¹ od iloœci przyk³adów. Nastêpnie 
zbiór przyk³adów zostanie podzielony na czêœæ treningow¹ i testow¹.
Porównywane modele zostan¹ nauczone u¿ywaj¹c zbioru treningowego, a nastêpnie
z u¿yciem zbioru testowego zostanie policzony b³¹d wzglêdny zgodnie z równaniem
\ref{eq:blad}. Im mniejszy b³¹d tym lepiej radzi sobie z generalizacj¹ dany klasyfikator.

\subsubsection{Szybkoœæ uczenia siê}
W wielu zastosowaniach szybkoœæ uczenia siê jest cech¹ drugorzêdn¹ je¿eli chodzi
o kryterium wyboru takiego czy innego aproksymatora. Dlatego te¿ zostanie zmierzony i porównany czas uczenia siê poszczególnych aproksymatorów dla 
kolejnych zestawów treningowych.

\bibliography{mow}
\end{document}
